{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOE2Br44qgXBREh4rZnWoeS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Liping-LZ/BDAO_DSDO/blob/main/Text_analysis/Sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Analysis-Read Me First**\n",
        "\n",
        "This is tutorial to show you how you can do sentiment analysis by using packages available in Google Colab. The package we are going to use are TextBlob and nltk sentiment vader.\n",
        "\n",
        "**TextBlob sentiment analysis** element can allow you to calculate the polarity score and subjectivity score of the text. The polarity score is a float within the range [-1.0, 1.0] where -1 is very negative and 1.0 is very positive. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective. Here is the documentation of TextBlob: https://textblob.readthedocs.io/en/dev/quickstart.html\n",
        "\n",
        "**Vader Sentiment analysis** is another approach for doing sentiment analysis, and VADER means Valence Aware Dictionary and Sentiment Reasoner.Vader is a lexicon and rule-based feeling analysis instrument that is explicitly sensitive to suppositions communicated in web-based media. Vader utilizes a mix of lexical highlights (e.g., words) that are, for the most part, marked by their semantic direction as positive or negative or neutral. Thus, Vader not only tells about the Polarity score yet, in addition, it tells us concerning how positive or negative a text is. What we are going to use the the vader analysis package from **NLTK** (which is a very famous library for NLP and you will see it a lot when we are doing other text mining tasks). By running the analysis using this package, you will get 4 polarity scores, namely compound, neg(ative), pos(itive), neu(tral). About the scoring, please check: https://github.com/cjhutto/vaderSentiment#about-the-scoring. Usually we use +-0.05 as benchmark to classify the sentence as positive or negative or neutral.\n",
        "\n",
        "Now is time to start trying with some examples. First, we try with single sentence, and then we will do sentiment analysis for multiple text imported as csv file.\n",
        "\n",
        "### **Let's start!**"
      ],
      "metadata": {
        "id": "eG2xd8MqD5BM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Sentiment analysis of single text**"
      ],
      "metadata": {
        "id": "hqwC-XSWx-2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we input a sentence as an example\n",
        "# Click the play button one the left in the each cell to run the code.\n",
        "sentence = \"The show is great and I would like to watch again\""
      ],
      "metadata": {
        "id": "0efQsEyeQtfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "# import the TextBlob package."
      ],
      "metadata": {
        "id": "aAepYY-1Q8QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TextBlob().sentiment is the method used to calculate the score. put the sentence/text into the bracket\n",
        "# After you run the code you will be able to see the scores.\n",
        "TextBlob(sentence).sentiment\n",
        "\n",
        "# the polarity is between [-1,1]. while closer to -1 is more negative, closer to 1 is more positive."
      ],
      "metadata": {
        "id": "UdIDV9kKQ-zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is another python package for sentiment analysis, and it's called nltk vader. SentimenIntensityAnalyzer() is the function.\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Before run the function, you need to import the nltk package and download the vader_lexicon first."
      ],
      "metadata": {
        "id": "v92Gmq-eRQRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now it's all set up and you need to import the sentiment_intensity_analyzer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "cs_5TDyNMKNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here you can use the analyzer function to calculate the score of the sentence.\n",
        "# After you run the function you should be able to see 4 scores.\n",
        "sid.polarity_scores(sentence)\n",
        "\n",
        "# same as textblob, the compound score is between -1 and 1, and closer to 1 the higher positivity of the text."
      ],
      "metadata": {
        "id": "i-BQXdSARqRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above are the simple examples of calculating sentiment score for single sentence. Below we are starting to do sentiment analysis using nltk sentiment vader for multiple text by importing the text file and output the sentiment analysis result as dataframe saved as csv file combiled with the original text as well."
      ],
      "metadata": {
        "id": "oTMvn8UGMpRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Sentiment analysis of batch text**"
      ],
      "metadata": {
        "id": "RgJKUDYjyJ5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Sentiment analysis with TextBlob"
      ],
      "metadata": {
        "id": "HgDVqeqir7cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Except for doing sentiment analysis for one single sentence, it's also available for you to import a dataframe and do the sentiment analysis for the whole batch.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# once you run this code, it will prompt you to select a file. You just need to \"Choose a file\" (any file you want to do sentiment analysis) from your laptop."
      ],
      "metadata": {
        "id": "oROgKhqysJM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# once you upload the data to the cloud, you can read the data into dataframe. Remember, if you close the notebook or disconnect, you need to upload the file (run the code above) again before you read data.\n",
        "\n",
        "import pandas as pd\n",
        "data_path = 'your_data_file' # change the csv file name to your file name that you uploaded\n",
        "df = pd.read_csv(data_path)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "sUzYyzvJsL7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the target column to the review column\n",
        "\n",
        "target_column = 'your_target_column'"
      ],
      "metadata": {
        "id": "sUrdpKMXpbWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you might need to do some text cleaning before sentiment analysis. One basic requirement for running the sentiment analysis function, you need to make sure the target column has no null values.\n",
        "df = df.dropna(subset = [target_column]) # Here I just delete the rows if the target column is null"
      ],
      "metadata": {
        "id": "Pu5ZXePtsN-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import numpy as np\n",
        "df['Polarity'] = df[target_column].apply(lambda review: TextBlob(str(review)).sentiment.polarity)\n",
        "df['Subjectivity'] = df[target_column].apply(lambda review: TextBlob(str(review)).sentiment.subjectivity)\n",
        "df['Sentiment'] = np.where(df['Polarity']>0, 'Positive',np.where(df['Polarity']<0,'Negative', 'Neutral')) # here we set 0 as the benchmark. you can adjust based on your data"
      ],
      "metadata": {
        "id": "5TwKSMJDsYds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort by polarity (low to high)\n",
        "sorted_df = df.sort_values(by=['Polarity'])\n",
        "\n",
        "# print top 5 positive and negative\n",
        "print(\"Most positive #5 reviews \")\n",
        "print(sorted_df[target_column].tail())\n",
        "print(\"\\n\") # print line break\n",
        "print(\"Most negative #5 reviews \")\n",
        "print(sorted_df[target_column].head())"
      ],
      "metadata": {
        "id": "hMS-Eo9Ls6yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment analysis visualisation\n",
        "import seaborn as sns\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "sns.countplot(x='Sentiment',data = df,order=['Positive','Neutral','Negative'])"
      ],
      "metadata": {
        "id": "lcioyfpQu7Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finally, save the new dataframe with all the scores to the local machine.\n",
        "\n",
        "df.to_csv('sentiment_textblob.csv', index=False) # save the file to google drive\n",
        "files.download('sentiment_textblob.csv') # download the file to your local machine"
      ],
      "metadata": {
        "id": "NpuVDV6vtEVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2 Sentiment analysis with NLTK VADER"
      ],
      "metadata": {
        "id": "LlYQgxIUsDal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Except for doing sentiment analysis for one single sentence, it's also available for you to import a dataframe and do the sentiment analysis for the whole batch.\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# once you run this code, it will prompt you to select a file. You just need to \"Choose a file\" (any file you want to do sentiment analysis) from your laptop."
      ],
      "metadata": {
        "id": "925CkwKtSUvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# once you upload the data to the cloud, you can read the data into dataframe. Remember, if you close the notebook or disconnect, you need to upload the file (run the code above) again before you read data.\n",
        "\n",
        "import pandas as pd\n",
        "data_path = 'Anydo_review_new.csv' # change the csv file name to your file name that you uploaded\n",
        "df = pd.read_csv(data_path) # change the csv file name to your file name that you uploaded\n",
        "df.head()"
      ],
      "metadata": {
        "id": "-jr4cstvUJqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the target column to the review column\n",
        "\n",
        "target_column = 'content'"
      ],
      "metadata": {
        "id": "R4s8cpqHqtY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you might need to do some text cleaning before sentiment analysis. One basic requirement for running the sentiment analysis function, you need to make sure the target column has no null values.\n",
        "df = df.dropna(subset = [target_column]) # Here I just delete the rows if the target column is null (in this case, it's \"Review\" column)"
      ],
      "metadata": {
        "id": "Kyms63IUi3DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first, import the package (suppose we haven't imported it yet) run the analyzer (SentimentIntensityAnalyzer())\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Then create new columns for your dataframe (compound, pos, neu, neg) with empty dictionary\n",
        "# With for loop, we get the scores for each review and append the scores to the dictionary\n",
        "\n",
        "Result = { 'compound':[], 'pos':[] , 'neu':[], 'neg':[] }\n",
        "\n",
        "for review in df[target_column]:\n",
        "    score = sid.polarity_scores(review)\n",
        "    Result['pos'].append(score['pos'])\n",
        "    Result['neu'].append(score['neu'])\n",
        "    Result['neg'].append(score['neg'])\n",
        "    Result['compound'].append(score['compound'])\n",
        "\n",
        "# Once this is done, new columns are created and dictionary is transformed to the dataframe\n",
        "\n",
        "df['compound'] = pd.DataFrame(Result)['compound']\n",
        "df['pos'] = pd.DataFrame(Result)['pos']\n",
        "df['neu'] = pd.DataFrame(Result)['neu']\n",
        "df['neg'] = pd.DataFrame(Result)['neg']\n",
        "df['sentiment'] = np.where(df['compound']>=0.05, 'Positive',np.where(df['compound']<=-0.05,'Negative', 'Neutral'))"
      ],
      "metadata": {
        "id": "RzDo_YN0Wgol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort by polarity (low to high)\n",
        "sorted_df = df.sort_values(by=['compound'])\n",
        "\n",
        "# print top 5 positive and negative\n",
        "print(\"Most positive #5 reviews \")\n",
        "print(sorted_df[target_column].tail())\n",
        "print(\"\\n\") # print line break\n",
        "print(\"Most negative #5 reviews \")\n",
        "print(sorted_df[target_column].head())"
      ],
      "metadata": {
        "id": "bJcMWkicJu7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment analysis visualisation\n",
        "import seaborn as sns\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "sns.countplot(x='sentiment',data = df,order=['Positive','Neutral','Negative'])"
      ],
      "metadata": {
        "id": "WTX8DJV3M97J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finally, save the new dataframe with all the scores to the local machine.\n",
        "\n",
        "df.to_csv('sentiment_nltk.csv', index=False) # save the file to google drive\n",
        "files.download('sentiment_nltk.csv') # download the file to your local machine"
      ],
      "metadata": {
        "id": "rPhTwWfzJyx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Hint for interpretation and analysis of the sentiment scores**\n",
        "\n",
        "Once you got your result, there is some tips for you to analyse your data. First, you can take a look at the distribution of the polarity (postive vs. negative) and have some overall ideas about the customer opinion; second, if you also have the rating score given by the users, you can compare the sentiment score you got with the rating and check whether there is gap between them. Sentiment analysis is not always reliable. Third, don't just look at the scores. You need to understand why the positive or negative reviews are given. And think how we can help improve the customer service or our product based on the customer feedback. you can take a look at some reviews with low or high polarity score and have some analysis on the content. You can also combine sentiment analysis and topic modeling so you can understand the key topics covered by spefic sentiment type of reviews. Please check another scripts about topic modeling."
      ],
      "metadata": {
        "id": "roEW62eNpLuS"
      }
    }
  ]
}